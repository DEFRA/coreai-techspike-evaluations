{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to venv (Python 3.10.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ad9648-7916-43ed-8a01-316f6003c78d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error raised by inference endpoint: HTTPConnectionPool(host='host.docker.internal', port=11434): Max retries exceeded with url: /api/embeddings (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fbf89e48d60>, 'Connection to host.docker.internal timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/urllib3/connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    197\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m    198\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    199\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[1;32m    200\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[1;32m    201\u001b[0m     )\n\u001b[1;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     74\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m     conn\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    496\u001b[0m         method,\n\u001b[1;32m    497\u001b[0m         url,\n\u001b[1;32m    498\u001b[0m         body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    499\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    500\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    501\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    502\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    503\u001b[0m         enforce_content_length\u001b[39m=\u001b[39;49menforce_content_length,\n\u001b[1;32m    504\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/urllib3/connection.py:398\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 398\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders()\n\u001b[1;32m    400\u001b[0m \u001b[39m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1278\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1038\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1040\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 976\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    977\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/urllib3/connection.py:236\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tunnel_host:\n\u001b[1;32m    238\u001b[0m         \u001b[39m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/urllib3/connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    206\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConnection to \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\u001b[39m}\u001b[39;00m\u001b[39m timed out. (connect timeout=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPConnection object at 0x7fbf89e48d60>, 'Connection to host.docker.internal timed out. (connect timeout=None)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    844\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    845\u001b[0m )\n\u001b[1;32m    846\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[39m=\u001b[39m error \u001b[39mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[39mfrom\u001b[39;00m \u001b[39mreason\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='host.docker.internal', port=11434): Max retries exceeded with url: /api/embeddings (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fbf89e48d60>, 'Connection to host.docker.internal timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/langchain_community/embeddings/ollama.py:164\u001b[0m, in \u001b[0;36mOllamaEmbeddings._process_emb_response\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mpost(\n\u001b[1;32m    165\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_url\u001b[39m}\u001b[39;49;00m\u001b[39m/api/embeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    166\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    167\u001b[0m         json\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_params},\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/requests/adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, NewConnectionError):\n\u001b[0;32m--> 688\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectTimeout(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    690\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, ResponseError):\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: HTTPConnectionPool(host='host.docker.internal', port=11434): Max retries exceeded with url: /api/embeddings (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fbf89e48d60>, 'Connection to host.docker.internal timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m/home/barry/repos/coreai-techspike-evaluations/app/app.py:119\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[39mprint\u001b[39m(result)\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m     main()\n",
      "File \u001b[1;32m/home/barry/repos/coreai-techspike-evaluations/app/app.py:108\u001b[0m\n\u001b[1;32m    106\u001b[0m documents \u001b[39m=\u001b[39m load_documents()\n\u001b[1;32m    107\u001b[0m docs \u001b[39m=\u001b[39m split_documents(documents)\n\u001b[0;32m--> 108\u001b[0m vectorstore \u001b[39m=\u001b[39m create_and_store_embeddings(docs)\n\u001b[1;32m    109\u001b[0m relevant_docs \u001b[39m=\u001b[39m retrieve_relevant_documents(vectorstore, question)\n\u001b[1;32m    111\u001b[0m model \u001b[39m=\u001b[39m initialize_model(model_name)\n",
      "File \u001b[1;32m/home/barry/repos/coreai-techspike-evaluations/app/app.py:58\u001b[0m\n\u001b[1;32m     55\u001b[0m connection_string \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpostgresql+psycopg2://\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mPOSTGRES_USERNAME\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mPOSTGRES_PASSWORD\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m@\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mPOSTGRES_HOST\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mPOSTGRES_PORT\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mPOSTGRES_DB\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m collection_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mPGVECTOR_COLLECTION_NAME\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m vectorstore \u001b[39m=\u001b[39m PGVector\u001b[39m.\u001b[39;49mfrom_documents(\n\u001b[1;32m     59\u001b[0m     embedding\u001b[39m=\u001b[39;49membeddings,\n\u001b[1;32m     60\u001b[0m     documents\u001b[39m=\u001b[39;49mdocs,\n\u001b[1;32m     61\u001b[0m     connection\u001b[39m=\u001b[39;49mconnection_string, \n\u001b[1;32m     62\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m     63\u001b[0m     use_jsonb\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     64\u001b[0m     async_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[39mreturn\u001b[39;00m vectorstore\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/langchain_postgres/vectorstores.py:1731\u001b[0m, in \u001b[0;36mPGVector.from_documents\u001b[0;34m(cls, documents, embedding, connection, collection_name, distance_strategy, ids, pre_delete_collection, use_jsonb, **kwargs)\u001b[0m\n\u001b[1;32m   1728\u001b[0m texts \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m   1729\u001b[0m metadatas \u001b[39m=\u001b[39m [d\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m-> 1731\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[1;32m   1732\u001b[0m     texts\u001b[39m=\u001b[39;49mtexts,\n\u001b[1;32m   1733\u001b[0m     pre_delete_collection\u001b[39m=\u001b[39;49mpre_delete_collection,\n\u001b[1;32m   1734\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m   1735\u001b[0m     distance_strategy\u001b[39m=\u001b[39;49mdistance_strategy,\n\u001b[1;32m   1736\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[1;32m   1737\u001b[0m     connection\u001b[39m=\u001b[39;49mconnection,\n\u001b[1;32m   1738\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m   1739\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m   1740\u001b[0m     use_jsonb\u001b[39m=\u001b[39;49muse_jsonb,\n\u001b[1;32m   1741\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1742\u001b[0m )\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/langchain_postgres/vectorstores.py:1494\u001b[0m, in \u001b[0;36mPGVector.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, collection_name, distance_strategy, ids, pre_delete_collection, use_jsonb, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1480\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_texts\u001b[39m(\n\u001b[1;32m   1481\u001b[0m     \u001b[39mcls\u001b[39m: Type[PGVector],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1492\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PGVector:\n\u001b[1;32m   1493\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return VectorStore initialized from documents and embeddings.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1494\u001b[0m     embeddings \u001b[39m=\u001b[39m embedding\u001b[39m.\u001b[39;49membed_documents(\u001b[39mlist\u001b[39;49m(texts))\n\u001b[1;32m   1496\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m__from(\n\u001b[1;32m   1497\u001b[0m         texts,\n\u001b[1;32m   1498\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   1507\u001b[0m     )\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/langchain_community/embeddings/ollama.py:211\u001b[0m, in \u001b[0;36mOllamaEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Embed documents using an Ollama deployed embedding model.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \n\u001b[1;32m    204\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m instruction_pairs \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_instruction\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts]\n\u001b[0;32m--> 211\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed(instruction_pairs)\n\u001b[1;32m    212\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/langchain_community/embeddings/ollama.py:199\u001b[0m, in \u001b[0;36mOllamaEmbeddings._embed\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     iter_ \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> 199\u001b[0m \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_emb_response(prompt) \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m iter_]\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/langchain_community/embeddings/ollama.py:199\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     iter_ \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> 199\u001b[0m \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_emb_response(prompt) \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m iter_]\n",
      "File \u001b[0;32m~/repos/coreai-techspike-evaluations/venv/lib/python3.10/site-packages/langchain_community/embeddings/ollama.py:170\u001b[0m, in \u001b[0;36mOllamaEmbeddings._process_emb_response\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(\n\u001b[1;32m    165\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_url\u001b[39m}\u001b[39;00m\u001b[39m/api/embeddings\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    166\u001b[0m         headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m    167\u001b[0m         json\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_params},\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 170\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError raised by inference endpoint: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m res\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    174\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError raised by inference API HTTP code: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[39m%\u001b[39m (res\u001b[39m.\u001b[39mstatus_code, res\u001b[39m.\u001b[39mtext)\n\u001b[1;32m    176\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Error raised by inference endpoint: HTTPConnectionPool(host='host.docker.internal', port=11434): Max retries exceeded with url: /api/embeddings (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7fbf89e48d60>, 'Connection to host.docker.internal timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "session_id = str(uuid.uuid4())\n",
    "\n",
    "langfuse_handler = CallbackHandler(\n",
    "  secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "  public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "  host=os.getenv(\"LANGFUSE_HOST\"),\n",
    "  session_id=session_id\n",
    ")\n",
    "\n",
    "def load_environment_variables():\n",
    "  load_dotenv()\n",
    "  model = os.getenv(\"MODEL_NAME\")\n",
    "  base_url = os.getenv(\"LANGFUSE_HOST\")\n",
    "  return model, base_url\n",
    "\n",
    "def load_documents():\n",
    "  current_directory = os.path.dirname(os.path.abspath(__file__))\n",
    "  docs_directory_path = os.path.join(current_directory, \"./docs\")\n",
    "  pdfs = [p for p in os.listdir(docs_directory_path) if p.endswith(\".pdf\")]\n",
    "  documents = []\n",
    "\n",
    "  for pdf in pdfs:\n",
    "      file_path = os.path.join(docs_directory_path, pdf)\n",
    "      loader = PyPDFLoader(file_path)\n",
    "      pdf_docs = loader.load()\n",
    "      documents.extend(pdf_docs)\n",
    "      for doc in pdf_docs:\n",
    "          documents.append(doc)\n",
    "\n",
    "  return documents\n",
    "\n",
    "def split_documents(documents):\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "  docs = text_splitter.split_documents(documents)\n",
    "  return docs\n",
    "\n",
    "def create_and_store_embeddings(docs):\n",
    "  embeddings = OllamaEmbeddings(base_url='http://host.docker.internal:11434', model='nomic-embed-text')\n",
    "  # doc_vectors = embeddings.embed_documents([t.page_content for t in docs])\n",
    "\n",
    "  connection_string = f\"postgresql+psycopg2://{os.getenv('POSTGRES_USERNAME')}:{os.getenv('POSTGRES_PASSWORD')}@{os.getenv('POSTGRES_HOST')}:{os.getenv('POSTGRES_PORT')}/{os.getenv('POSTGRES_DB')}\"\n",
    "  collection_name = os.getenv('PGVECTOR_COLLECTION_NAME')\n",
    "\n",
    "  vectorstore = PGVector.from_documents(\n",
    "      embedding=embeddings,\n",
    "      documents=docs,\n",
    "      connection=connection_string, \n",
    "      collection_name=collection_name,\n",
    "      use_jsonb=True,\n",
    "      async_mode=False,\n",
    "  )\n",
    "\n",
    "  return vectorstore\n",
    "\n",
    "def retrieve_relevant_documents(vectorstore, question):\n",
    "  retriever = vectorstore.as_retriever(\n",
    "      search_type=\"similarity_score_threshold\",\n",
    "      search_kwargs={'k': 5, 'score_threshold': 0.1}\n",
    "  )\n",
    "\n",
    "  relevant_docs = retriever.invoke(question)\n",
    "  return relevant_docs\n",
    "\n",
    "def initialize_model(model_name):\n",
    "  model = Ollama(\n",
    "      model=model_name,\n",
    "      temperature=2\n",
    "  )\n",
    "  return model\n",
    "\n",
    "def create_prompt_template():\n",
    "  template = \"\"\"Answer the question based on the following context: {context}\n",
    "  If you are unable to find the answer within the context, please respond with 'I don't know'.\n",
    "\n",
    "  Question: {question}\n",
    "  \"\"\"\n",
    "  prompt_template = ChatPromptTemplate.from_messages(\n",
    "      [\n",
    "          (\"system\", template),\n",
    "          (\"human\", \"{question}\")\n",
    "      ]\n",
    "  )\n",
    "  return prompt_template\n",
    "\n",
    "def create_chain(prompt_template, model):\n",
    "  chain = prompt_template | model | StrOutputParser()\n",
    "  return chain\n",
    "\n",
    "def main(q=\"What is the Annual budget?\"):\n",
    "  model_name, base_url = load_environment_variables()\n",
    "  question = q\n",
    "  documents = load_documents()\n",
    "  docs = split_documents(documents)\n",
    "  vectorstore = create_and_store_embeddings(docs)\n",
    "  relevant_docs = retrieve_relevant_documents(vectorstore, question)\n",
    "\n",
    "  model = initialize_model(model_name)\n",
    "  prompt_template = create_prompt_template()\n",
    "  chain = create_chain(prompt_template, model)\n",
    "\n",
    "  result = chain.invoke({\"context\": relevant_docs, \"question\": question}, config={\"callbacks\": [langfuse_handler]})\n",
    "  print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
